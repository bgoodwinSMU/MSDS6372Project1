---
title: "DS6372 Project 1"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

## Project 1, MSDS6372
# By Group 2: Helene, Ben, Will

```{r}
#Project Libraries
library(naniar)
library(caret)
library(ggplot2)
library(mlbench)
library(glmnet)
library(olsrr)
library(fmsb)
library(corrplot)
library(RColorBrewer)
library(funModeling)
library(tidyverse)
library(Hmisc)
library(kableExtra)

```




## Objective 1 Overview

Objective 1: Display the ability to build regression models using the skills and discussions from Unit 1 and 2 with the purpose of identifying key relationships and interpreting those relationships.  A key question of interest that must be addressed in this analysis is the importance of the “Popularity” variable.  While the details of this variable are vague, it was created from social media, and the “higher ups” are curious how much general popularity can play a role in the retail price of a vehicle.   

# Objective 1, Prelimenary Data Assessment and data parsing 

```{r}
#Read in the data file
proj1Dat <- read.csv("data1.csv")

vis_miss(proj1Dat)

#Make df to work with, so orginal data is untouched
carDat <- proj1Dat
carDat$MSRP <- log(carDat$MSRP)

#Examine data
#View(proj1Dat)

#See problems with missing data
new_DF <- proj1Dat[rowSums(is.na(proj1Dat)) > 0,]
#View(new_DF)

#Looks like data is pretty good, need to handle NA's for electric cars (cylinders)
#Proposed solution is  to change electric cars to 0 cylinders and convert to factor
#Also need to handle NA's for electric cars (horsepower)
#Proposed solution is to change horsepower to 0 and convert to factor
#Some mazda rx7 missing values
#Some mazda rx8 missing values

#Change NA's
carDat[is.na(carDat)] <- 0

#Now fix 8696-8698 with 2 cylinders
carDat[c(8696:8698),6] <- 2

#And fix 8699-8715 with 4 cylinders
carDat[c(8699:8715),6] <- 4

#And fix 4204-4207 with 168
carDat[c(4204:4207),5] <- 168

#And fix 4915-4920 with 193
carDat[c(4915:4920),5] <- 193

#And fix 5826,5831,5832,5834,5840,5841 with 301
carDat[c(5826,5831,5832,5840,5841),5] <- 301

#And fix 6909, 6911, 6917,6919 with 305
carDat[c(6909,6911,6917,6919),5] <- 305

#Convert to factors
carDat$Make <- as.factor(carDat$Make)
carDat$Year <- as.factor(carDat$Year)
carDat$Engine.Fuel.Type <- as.factor(carDat$Engine.Fuel.Type)
carDat$Transmission.Type <- as.factor(carDat$Transmission.Type)
carDat$Number.of.Doors <- as.factor(carDat$Number.of.Doors)
carDat$Market.Category <- as.factor(carDat$Market.Category)
carDat$Vehicle.Size <- as.factor(carDat$Vehicle.Size)
carDat$Vehicle.Style <- as.factor(carDat$Vehicle.Style)



#Look at missing data 
vis_miss(carDat)
#Looks good
```

# Split up data into 80% training, 10% testing, and 10% validation
```{r}
#time to split up the data .8 train, .1 test, .1 validate
ss <- sample(1:3,size=nrow(carDat),replace=TRUE,prob=c(0.8,0.1,0.1))
train <- carDat[ss==1,]
test <- carDat[ss==2,]
cvr <- carDat[ss==3,]
```





## Objective 1.1

Build a model with the main goal to identify key relationships and is highly interpretable.  Provide detailed information on summary statistics, EDA, and your model building process. 

```{r}

#Summary Statistics 
mean(carDat$Popularity)
min(carDat$Popularity)
max(carDat$Popularity)
sd(carDat$Popularity)

#General summary stats
summary(carDat)
summary(proj1Dat)

#Summary of vehicle style
summary(carDat$Vehicle.Style)
plot(carDat$Vehicle.Style)


p <- ggplot(carDat, aes(fill=Popularity, y=Vehicle.Style, x=MSRP)) + 
    geom_bar(position="dodge", stat="identity")
p + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

#EDA
ggplot(carDat, aes(x = MSRP, y = Popularity,color=Vehicle.Style)) 
  geom_point()

ggplot(data = carDat, mapping = aes(x = MSRP, y = Popularity)) +
    geom_point() +
    geom_smooth(aes(color = Vehicle.Style)) +
    facet_wrap( ~Vehicle.Style)



#Histogram of MSRP
ggplot(carDat, aes(x=(MSRP))) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 

#Log transformed history of MSRP
ggplot(carDat, aes(x=log(MSRP))) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 


#Histogram of popularity
ggplot(carDat, aes(x=(Popularity))) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 


M <-cor(carDat[,c(5,6,13,14,15,16)])
corrplot(M, type="upper", order="hclust",
         col=brewer.pal(n=8, name="RdYlBu"))

plotmatrix((carDat[,c(5,6,13,14,15,16)]))
ggpairs(carDat[,c(5,6,13,14,15,16)])
plot_num(carDat)


ggplot(carDat, aes(x=Engine.HP, y=MSRP)) + 
  geom_point()+
  geom_smooth(method = "lm")

ggplot(carDat, aes(x=Popularity, y=MSRP)) + 
  geom_point()+
  geom_smooth()

ggplot(carDat, aes(x=Vehicle.Style, y=MSRP)) + 
  geom_point()+
  geom_smooth() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(carDat, aes(x=Engine.Cylinders, y=MSRP)) + 
  geom_point()+
  geom_smooth() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))





```
```{r}
#Model Selection

reg.fwd=regsubsets(MSRP~.,data=train,method="forward",nvmax=15)
bics<-summary(reg.fwd)$bic
plot(bics,type="l",ylab="BIC",xlab="# of predictors")

reg.fwd$nbest

regfwdMdl <- lm(MSRP~.,data=train)
summary(regfwdMdl)

reg.bwd=regsubsets(MSRP~.,data=train,method="backward",nvmax=15)
bics<-summary(reg.bwd)$bic


# Adjr2
adjr2<-summary(reg.fwd)$adjr2
plot(adjr2,type="l",ylab="Adjusted R-squared",xlab="# of predictors")

 
MallowCP <- summary(reg.fwd)$cp
plot(MallowCP,type="l",ylab="Mallow's CP",xlab="# of predictors")



##Human model:

edaModel <- lm(MSRP~Engine.HP+Vehicle.Style+Engine.Cylinders,data=carDat)
summary(edaModel)

ols_plot_resid_fit(edaModel)
ols_plot_resid_lev(edaModel)
ols_plot_resid_qq(edaModel)
ols_plot_resid_hist(edaModel)
ols_plot_cooksd_bar(edaModel)

p <- predict(edaModel, cvr)
error <- (p- cvr$MSRP)
RMSE_Model <- sqrt(mean(error^2))

ptest <- predict(edaModel, test)
error1 <- (ptest- cvr$MSRP)
RMSE_NewData <- sqrt(mean(error1^2))
Method <- c("Train/Test Split")
ModelRMSE <- c(RMSE_Model)
RMSENewData <- c(RMSE_NewData)

table1 <- data.frame(Method, ModelRMSE, RMSENewData)

kable(table1) %>% kable_styling(c("striped", "bordered")) %>%column_spec(2:3, border_left = T)


#Full model
fullModel <- lm(MSRP~.,data = carDat)
summary(fullModel)
ols_plot_resid_fit(fullModel)
ols_plot_resid_lev(fullModel)
ols_plot_resid_qq(fullModel)
ols_plot_resid_hist(fullModel)
ols_plot_cooksd_bar(fullModel)

p <- predict(fullModel, test)
error <- (p- test$MSRP)
RMSE_Model <- sqrt(mean(error^2))

ptest <- predict(fullModel, test)
error1 <- (ptest- carDat$MSRP)
RMSE_NewData <- sqrt(mean(error1^2))
Method <- c("Train/Test Split")
ModelRMSE <- c(RMSE_Model)
RMSENewData <- c(RMSE_NewData)

table1 <- data.frame(Method, ModelRMSE, RMSENewData)

kable(table1) %>% kable_styling(c("striped", "bordered")) %>%column_spec(2:3, border_left = T)



# Set number of times you would like to repeat the sampling/testing 
iterations = 1:100
 
# the initial values for the columns (might not need these now that ive switched to building columns) 
rmseSimple = c()
rmseComplex = c()
 
 
# Start of Loop
for(i in iterations){
  # Resets sample every iteration 
  index<- sample(1:dim(carDat)[1],128,replace=F)
  train<- carDat[index,]
  test<- carDat[-index,]
  
 
  # the model runs 
  edaModel 
  
  fullModel 
  
  
  # predictors and column building
  predictions1 <- edaModel %>% predict(test)
  
  d1 = data.frame(R2 = R2(predictions1,test$MSRP),
                  RMSE = RMSE(predictions1,test$MSRP), MAE = MAE(predictions1, test$MSRP))
  rmseSimple = c(rmseSimple,d1$RMSE)
  
  predictions2 <- fullModel %>% predict(test)
 
  d2 = data.frame(R2 = R2(predictions2,test$MSRP),
                RMSE = RMSE(predictions2,test$MSRP), MAE = MAE(predictions2, test$MSRP))
  rmseComplex = c(rmseComplex, d2$RMSE)
  
 
  # End for
}

# putting the dataframe together and outputting relevant statistics
Model.Average.RMSE = cbind(rmseSimple, rmseComplex)
rmsedf = as.data.frame(Model.Average.RMSE)
Means = colMeans(Model.Average.RMSE)
SDs = round(colSds(Model.Average.RMSE), 3)
range1 = max(rmsedf$rmseSimple) - min(rmsedf$rmseSimple)
range2 = max(rmsedf$rmseComplex) - min(rmsedf$rmseComplex)
rmsedf1 = melt(rmsedf,rmse = c("n", "rmse"))



summary(Model.Average.RMSE)




Pred1 <- data.frame(Value = predictions1, Model = "Simple")
Pred2 <- data.frame(Value = predictions2, Model = "Complex")
PredActual <- data.frame(ActualValue = test$MSRP)
PredAll <- rbind(Pred1, Pred2)
PredActual <- rbind(PredActual,PredActual)
PredAll <- cbind(PredAll, PredActual)
PredAll %>% ggplot(aes(x = Value, y = ActualValue, fill = Model)) + geom_point(aes(color = Model)) + geom_smooth(formula = y~x)+theme_minimal()
 
# Column
rmsedf1 %>% group_by(variable) %>% summarise(mean = (mean(value))) %>% 
  ggplot(aes(x = reorder(variable, -mean), y = mean, fill = variable)) + geom_col(width = 0.75) + geom_text(aes(label = round(mean,3), vjust = -0.5)) + 
  ggtitle("Average RMSE over 100 Shuffles (Linear Models)") + xlab("Model #") + ylab("Mean RMSE")+theme_minimal()
 
# Boxplot
rmsedf1 %>%  ggplot(aes(x = variable, y = value)) + geom_boxplot(aes(fill = variable)) + facet_wrap(~variable,ncol = TRUE) +
  ggtitle("Mean RMSE Distribution by Model") + ylab("Mean RMSE") + coord_flip() + 
  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
# Histogram
rmsedf1 %>%  ggplot(aes(x = value)) + geom_histogram(aes(fill = variable)) + facet_wrap(~variable,ncol = TRUE) +
  ggtitle("Mean RMSE Distribution by Model") + xlab("Mean RMSE") + 
  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
 
# Here we can see there is no significant difference between the models in terms of RMSE
t.test(rmseSimple,rmseComplex, var.equal = FALSE)








```





## Objective 1.2

Provide interpretation of the regression coefficients of your final model including hypothesis testing, interpretation of regression coefficients, and confidence intervals. It’s also good to mention the Practical vs Statistical significance of the predictors.  Answer any additional questions using your model that you deem are relevant.

## Objective 1.3

The training data set can be used for EDA and model fitting while the test set can be used to help compare models to make a final call.  There is no need to use the validation data set for this objective.


# Practical Consideration for Objective 1:
EDA, EDA, EDA!  It helps you on so many fronts so use it to your advantage.  When writing a concise report, you do not have to literally step out every single step of your model building process.  I know you guys are going to being iterating on things many many times.  That does not all have to be there.  You can summarize that iteration stuff in a paragraph.  

What is key in the report is that you develop a “story” of your analysis.  Keep in mind that when you are finished with your analysis.  You know how it is going to end (what the final models look like).  You can use this to your advantage when selecting what parts of the EDA and additional information to show.  For example, if you know that predictor X7 is in your final model and it is one of the stronger relationships, that is probably a good one to show and discuss in the EDA part.  You would show the reader, “Hey look at these interesting trends”, “Hey look at these that are not”, etc.  When you report your final model and you are bringing back up the predictors discussed in EDA, it helps build the confidence of the reader in what you are doing is making sense.

```{r}
#Objective 2
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit <- train(MSRP ~., data = train[,c(5,6,13,14,15,16)], method = "knn",
 trControl=trctrl,
 preProcess = c("center", "scale"),
 tuneLength = 10)

(knn_fit)


test_pred <- predict(knn_fit, newdata = test)
test_pred

plot(knn_fit)
plot(knn_fit, print.thres = 0.5, type="S")


set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)

# Random forrest
rfFit <- train(MSRP ~ ., data = train[,c(5,6,13,14,15,16)], method = "rf", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)

rfFit
plot(rfFit)
```


